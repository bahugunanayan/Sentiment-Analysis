{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup: Beautiful Soup is a Python package for parsing HTML and XML documents. It creates parse trees that are helpful to extract the data easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requests module allows you to send HTTP requests using Python. The HTTP request returns a Response Object with all the response data (content, encoding, status, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/voice-tech-podcast/web-scraping-using-python-a89fc1609736\n",
    "\n",
    "\n",
    "for i in range (1,1000):\n",
    "    L='https://www.amazon.in/Samsung-Storage-Processor-Purchased-Separately/product-reviews/B09XJ5LD6L/pageNumber=3/ref='+'cm_cr_getr_d_paging_btm_next_'+str(i)+'?pageNumber='+str(i)\n",
    "    print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "review_content = []\n",
    "\n",
    "for i in range (1,100):\n",
    "    #Get the source HTML code as URL\n",
    "    page = requests.get('https://www.amazon.in/Oppo-Dynamic-Additional-Exchange-CPH2179/product-reviews/B08LRCMWKD/pageNumber=3/ref='+'cm_cr_getr_d_paging_btm_next_'+str(i)+'?pageNumber='+str(i))\n",
    "    #Convert that text into a bs4 lxml object\n",
    "    soup = bs(page.content,'html.parser')  \n",
    "    review = soup.find_all(\"span\",{\"data-hook\":\"review-body\"}) #Get the value(s) present in each tag into a list/tuple/dictionary\n",
    "    for i in range(0,len(review)):\n",
    "        review_content.append(review[i].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(review_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_content[:] = [reviews.lstrip('\\n') for reviews in review_content] #lstrip() method returns a copy of the string with leading characters removed (based on the string argument passed). If no argument is passed, it removes leading spaces.\n",
    "review_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_content[:] = [reviews.rstrip('\\n') for reviews in review_content] #The rstrip() method returns a copy of the string by removing the trailing characters specified as argument\n",
    "review_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['Reviews']=review_content\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                             Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean the Reviews\n",
    "import re\n",
    "\n",
    "def cleanTxt(text):\n",
    "    text=re.sub(r'@[A-Za-z0-9]','',text)  # Removed @ mentions\n",
    "    text=re.sub(r'#','',text)             # Removing '#' symbole\n",
    "    text=re.sub(r'RT[\\s]+','', text)      # Removing RT\n",
    "    text=re.sub(r'https?:\\/\\/S+','',text) # Removing the Hyperlink\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleanTxt on stored tweets\n",
    "df['Reviews']=df['Reviews'].apply(cleanTxt)\n",
    "df['Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # loading in all the essentials for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Ngrams allows to group words in common pairs or trigrams..etc\n",
    "from nltk import ngrams\n",
    "# We can use counter to count the objects\n",
    "from collections import Counter\n",
    "# This is our visual library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "sentence=df['Reviews'].to_string()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates tokens, creates lower class, removes numbers and lemmatizes the words\n",
    "new_tokens = word_tokenize(sentence)\n",
    "new_tokens = [t.lower() for t in new_tokens]\n",
    "new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "#counts the words, pairs and trigrams\n",
    "\n",
    "counted = Counter(new_tokens)\n",
    "counted_2= Counter(ngrams(new_tokens,2))\n",
    "counted_3= Counter(ngrams(new_tokens,3))\n",
    "counted_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creates 3 data frames and returns thems\n",
    "word_freq = pd.DataFrame(counted.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "word_pairs =pd.DataFrame(counted_2.items(),columns=['pairs','frequency']).sort_values(by='frequency',ascending=False)\n",
    "trigrams =pd.DataFrame(counted_3.items(),columns=['trigrams','frequency']).sort_values(by='frequency',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WordCloud\n",
    "! pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(max_words = 70, background_color = 'yellow').generate((sentence))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplot of the different data frames and draw graphs\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(8,20))\n",
    "sns.barplot(ax=axes[0],x='frequency',y='word',data=word_freq.head(30))\n",
    "sns.barplot(ax=axes[1],x='frequency',y='pairs',data=word_pairs.head(30))\n",
    "sns.barplot(ax=axes[2],x='frequency',y='trigrams',data=trigrams.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Preparing an input sentence\n",
    "\n",
    "sentence = 'I am  happy with product, Please throw it'\n",
    "analysisPol = TextBlob(sentence).polarity  # Polarity ranges from -1 to +1. \n",
    "# -1==Negative sentiment  0= neutral sentiment  +1=Positive sentiment\n",
    "analysisSub = TextBlob(sentence).subjectivity  # 0 (subjectivity) to 1(no subjectivity)\n",
    "\n",
    "print(analysisPol)\n",
    "print(analysisSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the subjectivity and polarity\n",
    "\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "\n",
    "df['TextBlob_Subjectivity']=df['Reviews'].apply(getSubjectivity)\n",
    "df['TextBlob_Polarity']=df['Reviews'].apply(getPolarity)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to decide the negative and positive sentiment based on polarity score\n",
    "\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['Sentiment'] = df['TextBlob_Polarity'].apply(getAnalysis )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of tweets based on sentiment score or polarity\n",
    "df ['Sentiment'] .value_counts().plot(kind='bar')\n",
    "df ['Sentiment'] .value_counts()/df ['Sentiment'] .value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
